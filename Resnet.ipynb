{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resnet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjr1VpyFMV1+H8OJTTZH7A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CXDshe_S9grl"},"source":["#ResNet (Residual Network)\n","\n","Mạng ResNet (R) là một mạng CNN được thiết kế để làm việc với hàng trăm hoặc hàng nghìn lớp chập. Một vấn đề xảy ra khi xây dựng mạng CNN với nhiều lớp chập sẽ xảy ra hiện tượng **Vanishing Gradient** dẫn tới quá trình học tập không tốt.\n","\n","Hiệu quả khi train các network cực kì sâu\n","\n","**Kiến trúc mạng Resnet**\n","\n","ResNet đưa ra là sử dụng kết nối \"tắt\" đồng nhất để xuyên qua một hay nhiều lớp. Một khối như vậy được gọi là một Residual Block.\n","\n","![Resnet](https://images.viblo.asia/9fc720ba-45e4-4d2f-8b58-5926350bc075.png)\n","\n","**ResNet** gần như tương tự với các mạng gồm có convolution, pooling, activation và fully-connected layer. Ảnh bên trên hiển thị khối dư được sử dụng trong mạng.\n","- F(X) = *X->weight1->RLU->weight2* là giá trị thật(nhãn)\n","- H(X) = *F(X)+x->ReLU*, là giá trị dự đoán\n","\n","Như chúng ta đã biết việc tăng số lượng các lớp trong mạng làm giảm độ chính xác, nhưng muốn có một kiến trúc mạng sâu hơn có thể hoạt động tốt.\n","\n","![Image](https://www.researchgate.net/profile/Xiao-Wang-160/publication/330553565/figure/fig9/AS:718079331930112@1548214862864/Architecture-of-VGG-19-34-layer-plain-and-Residual-Network34-for-ImageNet.ppm)\n","\n","- VGG-19 là một mô hình CNN sử dụng kernel 3x3 trên toàn bộ mạng.\n","- ResNet sử dụng các kết nối tắt ( kết nối trực tiếp đầu vào của lớp (n) với (n+x) được hiển thị dạng mũi tên cong. Qua mô hình nó chứng minh được có thể cải thiện hiệu suất trong quá trình training model khi mô hình có hơn 20 lớp.\n","- Tổng cộng có 12 đầu ra từ ResNet-152 và VGG-19 đã được sử dụng làm đầu vào cho mạng có 2 lớp hidden. Đầu ra cuối cùng được tính toán thông qua hai lớp ẩn ( hidden).\n","\n","**Xây dựng mạng ResNet-50**\n","\n","![Noron ResNet](https://images.viblo.asia/fe5b21e5-3ad3-4419-93e0-7aa77a662bdd.png)\n","\n","\"ID BLOCK\" trong hình trên là viết tắt của từ Identity block và ID BLOCK x3 nghĩa là có 3 khối Identity block chồng lên nhau. Nội dung hình trên như sau :\n","\n","- Zero-padding : Input với (3,3)\n","- Stage 1 : Tích chập (Conv1) với 64 filters với shape(7,7), sử dụng stride (2,2). BatchNorm, MaxPooling (3,3).\n","- Stage 2 : Convolutiontal block sử dụng 3 filter với size 64x64x256, f=3, s=1. Có 2 Identity blocks với filter size 64x64x256, f=3.\n","- Stage 3 : Convolutional sử dụng 3 filter size 128x128x512, f=3,s=2. Có 3 Identity blocks với filter size 128x128x512, f=3.\n","- Stage 4 : Convolutional sử dụng 3 filter size 256x256x1024, f=3,s=2. Có 5 Identity blocks với filter size 256x256x1024, f=3.\n","- Stage 5 :Convolutional sử dụng 3 filter size 512x512x2048, f=3,s=2. Có 2 Identity blocks với filter size 512x512x2048, f=3.\n","- The 2D Average Pooling : sử dụng với kích thước (2,2).\n","The Flatten.\n","- Fully Connected (Dense) : sử dụng softmax activation.\n","\n","**ID Block**\n","\n","Here is identity block:\n","\n","![Identiy](https://i.stack.imgur.com/37qzA.png)\n","\n","and here is convolutional block:\n","\n","![cblock](https://i.stack.imgur.com/0mE2p.png)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_9gmNWDn-Bre"},"source":["**Batch Nomalization**\n","\n","Input: Values of $x$ over a mini-batch: $B = \\{x_{1}...m\\}$ Parameters to be learned: $\\gamma,\\beta$\n","\n","Output: $\\{ y_{i} = BN_{\\gamma,\\beta} (x_{i})\\}$\n","\n","$\\mu_{B} \\leftarrow \\frac{1}{m} \\sum _{i=1}^{m} x_{i}  //mini -bacthmean$\n","\n","$\\sigma_{B}^{2} \\leftarrow \\frac{1}{m} \\sum _{i=1}^{m} (x_{i} - \\mu_{B})^{2} //mini - batchvariance$\n","\n","$\\widehat{x}_{i} \\leftarrow \\frac{x_{i} - \\mu_{B}}{\\sqrt{\\sigma^{2}_{B} + \\epsilon}} //normalize$\n","\n","$y_{i} \\leftarrow \\gamma \\widehat{x}_{i} + \\beta \\equiv BN_{\\gamma, \\beta}(x_{i}) \\text{\\\\\\scale and shift}$\n","\n","- Đặt trước activation\n","- Kéo ra khỏi điểm bão hòa (vanishing)\n","- Giúp đầu vào ổn định, dù data thay đổi nhiều\n","> Đạo hàm tốt hơn. Đạo hàm có cả *x* không chỉ có weight trong đấy thì *x* ổn định => output ổn đinh.\n","- Tránh overfiting.\n","- lúc training bắt buộc batch size > 1 (vì nếu là 1 nó là chính nó x hat = 0)\n","- batch nom có weight có training, nhưng không dùng gradient để tối ưu."]},{"cell_type":"code","metadata":{"id":"iRubbnQLAaGr"},"source":["import numpy as np\n","\n","def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum, is_training):\n","    # Use `autograd` to determine whether the current mode is training mode or\n","    # prediction mode\n","    if not is_training:\n","        # If it is prediction mode, directly use the mean and variance\n","        # obtained by moving average\n","        X_hat = (X - moving_mean) / np.sqrt(moving_var + eps)\n","    else:\n","        assert len(X.shape) in (2, 4)# for debugging\n","        if len(X.shape) == 2:\n","            # When using a fully-connected layer, calculate the mean and\n","            # variance on the feature dimension\n","            mean = X.mean(axis=0)\n","            var = ((X - mean)**2).mean(axis=0)\n","        else:\n","            # When using a two-dimensional convolutional layer, calculate the\n","            # mean and variance on the channel dimension (axis=1). Here we\n","            # need to maintain the shape of `X`, so that the broadcasting\n","            # operation can be carried out later\n","            mean = X.mean(axis=(0, 2, 3), keepdims=True)\n","            var = ((X - mean)**2).mean(axis=(0, 2, 3), keepdims=True)\n","        # In training mode, the current mean and variance are used for the\n","        # standardization\n","        X_hat = (X - mean) / np.sqrt(var + eps)\n","        # Update the mean and variance using moving average\n","        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n","        moving_var = momentum * moving_var + (1.0 - momentum) * var\n","    Y = gamma * X_hat + beta  # Scale and shift\n","    return Y, moving_mean, moving_var"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUB-y6VGNh9Z"},"source":["import numpy as np\n","from keras import layers\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from keras.models import Model, load_model\n","from keras.preprocessing import image\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras.applications.imagenet_utils import preprocess_input\n","import pydot\n","from IPython.display import SVG\n","from keras.initializers import glorot_uniform\n","import scipy.misc\n","from matplotlib.pyplot import imshow\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQydg5r0E6JW"},"source":["# GRADED FUNCTION: identity_block\n","\n","def identity_block(X, f, filters, stage, block):\n","    \"\"\"\n","    Implementation of the identity block as defined in Figure 3\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    \n","    Returns:\n","    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value. You'll need this later to add back to the main path. \n","    X_shortcut = X\n","    \n","    # First component of main path\n","    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = Activation('relu')(X)\n","    \n","    ### START CODE HERE ###\n","    \n","    # Second component of main path (≈3 lines)\n","    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n","    X = Activation('relu')(X)\n","\n","    # Third component of main path (≈2 lines)\n","    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = Add()([X_shortcut, X]) \n","    X = Activation('relu')(X)\n","    \n","    ### END CODE HERE ###\n","    \n","    return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYeA1Cq0J5TT"},"source":["# GRADED FUNCTION: convolutional_block\n","\n","def convolutional_block(X, f, filters, stage, block, s = 2):\n","    \"\"\"\n","    Implementation of the convolutional block as defined in Figure 4\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    s -- Integer, specifying the stride to be used\n","    \n","    Returns:\n","    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value\n","    X_shortcut = X\n","\n","\n","    ##### MAIN PATH #####\n","    # First component of main path \n","    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = Activation('relu')(X)\n","    \n","    ### START CODE HERE ###\n","\n","    # Second component of main path (≈3 lines)\n","    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n","    X = Activation('relu')(X)\n","\n","    # Third component of main path (≈2 lines)\n","    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n","\n","    ##### SHORTCUT PATH #### (≈2 lines)\n","    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n","    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = Add()([X, X_shortcut])\n","    X = Activation('relu')(X)\n","    \n","    ### END CODE HERE ###\n","    \n","    return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaG5zyKrKDFY"},"source":["# GRADED FUNCTION: ResNet50\n","\n","def ResNet50(input_shape=(64, 64, 3), classes=6):\n","    \"\"\"\n","    Implementation of the popular ResNet50 the following architecture:\n","    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n","    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n","\n","    Arguments:\n","    input_shape -- shape of the images of the dataset\n","    classes -- integer, number of classes\n","\n","    Returns:\n","    model -- a Model() instance in Keras\n","    \"\"\"\n","\n","    # Define the input as a tensor with shape input_shape\n","    X_input = Input(input_shape)\n","\n","    # Zero-Padding\n","    X = ZeroPadding2D((3, 3))(X_input)\n","\n","    # Stage 1\n","    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n","\n","    # Stage 2\n","    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n","\n","    ### START CODE HERE ###\n","\n","    # Stage 3 (≈4 lines)\n","    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n","\n","    # Stage 4 (≈6 lines)\n","    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    # Stage 5 (≈3 lines)\n","    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n","    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n","\n","    ### END CODE HERE ###\n","\n","    # output layer\n","    X = Flatten()(X)\n","    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n","\n","    # Create model\n","    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"IG_Bdn9vO2TQ","executionInfo":{"status":"ok","timestamp":1622383857196,"user_tz":-420,"elapsed":22970,"user":{"displayName":"Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5U-zs-8ujhQaCpvDo03iequwy5RSKEnhRnwQGQ=s64","userId":"11702303910424597473"}},"outputId":"15a47987-cd97-4d9e-d235-1021405b8977"},"source":["from google.colab import drive\n","import os\n","\n","drive.mount(\"/content/drive\")\n","path = '/content/drive/MyDrive/Colab Notebooks/Data'\n","os.chdir(path)\n","os.listdir()\n","\n","import pandas as pd\n","import glob2\n","import matplotlib.pyplot as plt\n","\n","dogs = glob2.glob('Train_Data/dog/*.jpg')\n","dog_labels = ['dog']*len(dogs)\n","cats = glob2.glob('Train_Data/cat/*.jpg')\n","cat_labels = ['cat']*len(cats)\n","\n","labels = dog_labels + cat_labels\n","image_links = dogs + cats\n","\n","data = pd.DataFrame({'labels': labels, 'image_links':image_links})\n","\n","data.groupby(labels).image_links.count().plot.bar()\n","plt.title('Number of images in each class')\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLsQ5FF2O3NI","executionInfo":{"status":"ok","timestamp":1622384044393,"user_tz":-420,"elapsed":781,"user":{"displayName":"Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5U-zs-8ujhQaCpvDo03iequwy5RSKEnhRnwQGQ=s64","userId":"11702303910424597473"}},"outputId":"23da3e62-afd2-4683-9f99-f13dba3da477"},"source":["from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.vgg16 import decode_predictions\n","Y = LabelBinarizer().fit_transform(data.labels)\n","\n","X=[]\n","for link in data[0:10].image_links:\n","  # load an image from file\n","  image = load_img(link, target_size=(224, 224))\n","  # convert the image pixels to a numpy array\n","  image = img_to_array(image)\n","  # reshape data for the model\n","  image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n","  # prepare the image for the VGG model\n","  image = preprocess_input(image)\n","  X.append(image)\n","\n","X=np.asarray(X)\n","\n","print(X.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm4Ey8QgPqvi","executionInfo":{"status":"ok","timestamp":1622384209835,"user_tz":-420,"elapsed":348,"user":{"displayName":"Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5U-zs-8ujhQaCpvDo03iequwy5RSKEnhRnwQGQ=s64","userId":"11702303910424597473"}},"outputId":"fcf44824-a2f2-4794-dc22-89ecea0dfa09"},"source":["from keras.utils.np_utils import to_categorical\n","Y = to_categorical(Y)\n","\n","X_test=X[5:]\n","Y_test=Y[5:]\n","\n","X_train=X[0:5]\n","Y_train=Y[0:5]\n","\n","print(X_test.shape, Y_test.shape, X_train.shape,Y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(5, 224, 224, 3) (1394, 2) (5, 224, 224, 3) (5, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qidEm8KmTPZG"},"source":["modelRN = ResNet50(input_shape=(224,224,3),classes=2)\n","modelRN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7QNC5NET_Qx","executionInfo":{"status":"ok","timestamp":1622384253507,"user_tz":-420,"elapsed":38698,"user":{"displayName":"Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5U-zs-8ujhQaCpvDo03iequwy5RSKEnhRnwQGQ=s64","userId":"11702303910424597473"}},"outputId":"50e5234a-96fb-4870-be47-3f2565bb8bbd"},"source":["modelRN.fit(x=X_train,y=Y_train,epochs=3,batch_size = 32)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","1/1 [==============================] - 21s 21s/step - loss: 1.2080 - accuracy: 0.2000\n","Epoch 2/3\n","1/1 [==============================] - 3s 3s/step - loss: 5.2863e-18 - accuracy: 1.0000\n","Epoch 3/3\n","1/1 [==============================] - 3s 3s/step - loss: 3.2014e-24 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f98e4d5d550>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"CNAD9qTkonz_"},"source":[""],"execution_count":null,"outputs":[]}]}